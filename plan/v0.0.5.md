# VSCode Semantic Search Extension - v0.0.5

## Focus: Smarter Code Chunking

Improve how files are split into chunks before embedding, to reduce wasted tokens and improve semantic search quality.

## Goals

- **Use tokens as the primary unit** for chunking instead of lines.
- **Support configurable max tokens per chunk** (default 1024, hard cap 2048).
- **Integrate `tiktoken` token counting** in the extension pipeline.
- **Tune overlap using lines** to keep context while avoiding excessive duplication.

## Design

1. **Token-based chunking core**
   - Replace current line-based chunking with a token-based splitter.
   - Use `tiktoken` (or `tiktoken-node`) with the target model's encoding.
   - Define chunk size in tokens: `defaultMaxTokens = 1024`, `absoluteMaxTokens = 2048`.

2. **Overlap and context handling**
   - Implement overlap in **tokens**, but align boundaries to **nearest line breaks** to keep chunks readable.
   - Use a small line-based adjustment (e.g. trim leading/trailing partial lines) to slightly shorten and clean chunk edges.
   - Make overlap ratio configurable (e.g. 10–20%).

3. **Configuration surface**
   - Add settings under `semantic-search.indexing`:
     - `chunkMaxTokens` (default 1024, min 256, max 2048).
     - `chunkOverlapTokens` (default 128–256, capped so `overlap < maxTokens`).
   - Validate and clamp user-provided values at runtime.

4. **Integration points**
   - Update the indexing pipeline in `IndexingService` (and any helpers) to:
     - Load the tokenizer once per process / per model.
     - Split file content into token-based chunks respecting max/overlap settings.
     - Store token-aware metadata (start/end token indices + line ranges) for better result snippets.

5. **Performance & fallback**
   - Cache tokenizer instances and avoid repeated encoding work where possible.
   - If `tiktoken` fails or is unavailable, fall back to the existing line-based splitter with a clear warning.

## Testing

- Unit tests for:
  - Token counting and chunk splitting boundaries (size, overlap, line alignment).
  - Configuration clamping and invalid value handling.
- Integration tests for:
  - Indexing a sample workspace and verifying chunk counts and sizes.
  - Search quality sanity check (no obvious truncation or over-duplication).
